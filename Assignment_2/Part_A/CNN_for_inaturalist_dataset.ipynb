{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final_of_Assignment_2_CS6910_Part_A_Updated_Sweep (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn9cRipGjFOQ"
      },
      "source": [
        "#**Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccS87o9spZb"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOUCAu_Wl1p"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFS2h0wwECp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c10b68c-bea6-4779-8a0a-8350c6272962"
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders as sf\n",
        "import torch\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.7/dist-packages (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaIqN9wjt-m"
      },
      "source": [
        "#**Downloading inatuaralist dataset zip file from drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h6FvpYBs0KP"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jdVoAts2F9"
      },
      "source": [
        "id = '19EA0yl7PM8i6aQTdhH0OiEyLcTsf6hmx'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbpwAIzRtpBJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('nature_12K.zip')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-QHFSsikACN"
      },
      "source": [
        "#**Unzipping the content and distributing in train, validation and test folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9c7EDQVxVPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07dfa37-81de-4757-ea98-eac275d95b23"
      },
      "source": [
        "!apt install unzip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9BplLq0upK"
      },
      "source": [
        "!unzip 'nature_12K.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPjujyZ4WVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0720fb59-eec6-442b-aaba-88a0625606f6"
      },
      "source": [
        "road='/content/inaturalist_12K/'\n",
        "roadtrn=road+\"train\"\n",
        "op= road+\"trainvalsplit\"\n",
        "sf.fixed(roadtrn, op, seed=1337, fixed=100, oversample=False, group_prefix=None)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 9999 files [01:20, 124.58 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtUjXFVkM5I"
      },
      "source": [
        "#**Preprocessing the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARbVL1JnAlyd"
      },
      "source": [
        "#preprocessing train data\n",
        "train_data = []\n",
        "train_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/train/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "data_augmentation = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    #print(image_folder_path)\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = data_augmentation(image)\n",
        "            train_data.append((normalized_image, i))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwzK2bv2dDC"
      },
      "source": [
        "#preprocessing validation data\n",
        "val_data = []\n",
        "val_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/val/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    #print(image_folder_path)\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = transform(image)\n",
        "            val_data.append((normalized_image, i))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRyije1hAoNm"
      },
      "source": [
        "# #preprocessing test data\n",
        "# test_data = []\n",
        "# test_label = []\n",
        "# path = '/content/inaturalist_12K/val/'\n",
        "# items = os.listdir(path)\n",
        "# items.sort()\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# for i in range(10):\n",
        "#     image_folder_path = path + items[i]\n",
        "#     #print(image_folder_path)\n",
        "#     image_names = os.listdir(image_folder_path)\n",
        "#     for each_image in image_names:\n",
        "#         if each_image.endswith(\".jpg\"):\n",
        "#             full_path = image_folder_path + '/' + each_image\n",
        "#             image = Image.open(full_path)\n",
        "#             image = image.resize((224,224))\n",
        "#             if image.mode == 'L':\n",
        "#                 continue\n",
        "#             normalized_image = transform(image)\n",
        "#             test_data.append((normalized_image, i))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6MQeNA16wda"
      },
      "source": [
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', \n",
        "           'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnQKCaUzkr9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20y48rirkifA"
      },
      "source": [
        "#**Constructing Convolution Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P606Okg1bgJa"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, dropout, channels, activation, ks, fc_neurons):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        if activation == 'ReLU':\n",
        "          self.activation = nn.ReLU()\n",
        "        elif activation == 'LeakyReLU':\n",
        "          self.activation = nn.LeakyReLU()\n",
        "        elif activation == 'ELU':\n",
        "          self.activation = nn.ELU()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = channels[0], kernel_size = ks[0])\n",
        "        torch.nn.init.xavier_normal_(self.conv1.weight)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels = channels[0], out_channels = channels[1], kernel_size = ks[1])\n",
        "        torch.nn.init.xavier_normal_(self.conv2.weight)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels = channels[1], out_channels = channels[2], kernel_size = ks[2])\n",
        "        torch.nn.init.xavier_normal_(self.conv3.weight)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(in_channels = channels[2], out_channels = channels[3], kernel_size = ks[3])\n",
        "        torch.nn.init.xavier_normal_(self.conv4.weight)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(in_channels = channels[3], out_channels = channels[4], kernel_size = ks[4])\n",
        "        torch.nn.init.xavier_normal_(self.conv5.weight)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(in_features = channels[4]*2*2, out_features = fc_neurons).to(device)\n",
        "        torch.nn.init.xavier_normal_(self.fc.weight).to(device)        \n",
        "        self.op = nn.Linear(in_features = fc_neurons, out_features = 10).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.activation(self.conv1(x)))\n",
        "        x = self.pool2(self.activation(self.conv2(x)))\n",
        "        x = self.pool3(self.activation(self.conv3(x)))\n",
        "        x = self.pool4(self.activation(self.conv4(x)))\n",
        "        x = self.pool5(self.activation(self.conv5(x)))\n",
        "        \n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = self.dropout(x)        \n",
        "        x = self.activation(self.fc(x))\n",
        "        x = self.op(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvTN4XyUKU6d"
      },
      "source": [
        "#training fucntion for CNN\n",
        "def train_model(model, criteria, optimizer, num_epochs=5, device='cuda'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs ))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode                \n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            if phase == 'train':\n",
        "                f = train_loader                \n",
        "            else:\n",
        "                f = val_loader\n",
        "            for inputs, labels in f:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criteria(outputs, labels)\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "            if phase == 'train':\n",
        "                epoch_loss = running_loss / len(train_data)\n",
        "                epoch_acc = running_corrects.double() /len(train_data)\n",
        "            else:\n",
        "                epoch_loss = running_loss / len(val_data)\n",
        "                epoch_acc = running_corrects.double() / len(val_data)\n",
        "            epoch_acc*=100\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best validation acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    # return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbe02wyolV6P"
      },
      "source": [
        "#**Defining data loaders and training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbmKOL6fSl3W"
      },
      "source": [
        "torch.manual_seed(50)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=200, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG5LnNBBpaSB",
        "outputId": "ca467644-dc3a-455a-9826-fee2ed2f9c57"
      },
      "source": [
        "model = ConvNet(0.25, [32, 64, 128, 256, 512], 'ReLU', [5]*5, 512).to(device)\n",
        "num_epochs = 10 \n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999))\n",
        "train_model(model, criteria, optimizer, num_epochs, 'cuda')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 2.2321 Acc: 16.1609\n",
            "valid Loss: 2.1616 Acc: 18.7187\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 2.1268 Acc: 22.0518\n",
            "valid Loss: 2.0661 Acc: 26.4264\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 2.0277 Acc: 27.1646\n",
            "valid Loss: 1.9995 Acc: 27.5275\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 1.9536 Acc: 30.5546\n",
            "valid Loss: 1.9475 Acc: 29.4294\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 1.8836 Acc: 33.6112\n",
            "valid Loss: 1.8695 Acc: 31.7317\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 1.8257 Acc: 35.7008\n",
            "valid Loss: 1.8540 Acc: 33.5335\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 1.7763 Acc: 37.4347\n",
            "valid Loss: 1.8058 Acc: 34.9349\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 1.7131 Acc: 40.3579\n",
            "valid Loss: 1.7769 Acc: 36.2362\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 1.6535 Acc: 42.6253\n",
            "valid Loss: 1.8003 Acc: 37.5375\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 1.5842 Acc: 44.7260\n",
            "valid Loss: 1.7661 Acc: 37.4374\n",
            "Training complete in 4m 15s\n",
            "Best val Acc: 37.537538\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}