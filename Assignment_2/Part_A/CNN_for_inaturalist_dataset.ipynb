{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final_of_Assignment_2_CS6910_Part_A_Updated_Sweep (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn9cRipGjFOQ"
      },
      "source": [
        "#**Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccS87o9spZb"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOUCAu_Wl1p"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFS2h0wwECp"
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders as sf\n",
        "import torch\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScwfwCl_fA9J"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaIqN9wjt-m"
      },
      "source": [
        "#**Downloading inatuaralist dataset zip file from drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h6FvpYBs0KP"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jdVoAts2F9"
      },
      "source": [
        "id = '19EA0yl7PM8i6aQTdhH0OiEyLcTsf6hmx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbpwAIzRtpBJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('nature_12K.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-QHFSsikACN"
      },
      "source": [
        "#**Unzipping the content and distributing in train, validation and test folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9c7EDQVxVPC"
      },
      "source": [
        "!apt install unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9BplLq0upK"
      },
      "source": [
        "!unzip 'nature_12K.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPjujyZ4WVU"
      },
      "source": [
        "road='/content/inaturalist_12K/'\n",
        "roadtrn=road+\"train\"\n",
        "op= road+\"trainvalsplit\"\n",
        "sf.fixed(roadtrn, op, seed=1337, fixed=100, oversample=False, group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtUjXFVkM5I"
      },
      "source": [
        "#**Preprocessing the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARbVL1JnAlyd"
      },
      "source": [
        "#preprocessing train data\n",
        "train_data = []\n",
        "train_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/train/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "data_augmentation = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    #print(image_folder_path)\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = data_augmentation(image)\n",
        "            train_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwzK2bv2dDC"
      },
      "source": [
        "#preprocessing validation data\n",
        "val_data = []\n",
        "val_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/val/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    #print(image_folder_path)\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = transform(image)\n",
        "            val_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRyije1hAoNm"
      },
      "source": [
        "# #preprocessing test data\n",
        "# test_data = []\n",
        "# test_label = []\n",
        "# path = '/content/inaturalist_12K/val/'\n",
        "# items = os.listdir(path)\n",
        "# items.sort()\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# for i in range(10):\n",
        "#     image_folder_path = path + items[i]\n",
        "#     #print(image_folder_path)\n",
        "#     image_names = os.listdir(image_folder_path)\n",
        "#     for each_image in image_names:\n",
        "#         if each_image.endswith(\".jpg\"):\n",
        "#             full_path = image_folder_path + '/' + each_image\n",
        "#             image = Image.open(full_path)\n",
        "#             image = image.resize((224,224))\n",
        "#             if image.mode == 'L':\n",
        "#                 continue\n",
        "#             normalized_image = transform(image)\n",
        "#             test_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6MQeNA16wda"
      },
      "source": [
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', \n",
        "           'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnQKCaUzkr9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20y48rirkifA"
      },
      "source": [
        "#**Constructing Convolution Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P606Okg1bgJa"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, dropout, channels, activation, ks, fc_neurons):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        if activation == 'ReLU':\n",
        "          self.activation = nn.ReLU()\n",
        "        elif activation == 'LeakyReLU':\n",
        "          self.activation = nn.LeakyReLU()\n",
        "        elif activation == 'ELU':\n",
        "          self.activation = nn.ELU()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = channels[0], kernel_size = ks[0])\n",
        "        torch.nn.init.xavier_normal_(self.conv1.weight)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels = channels[0], out_channels = channels[1], kernel_size = ks[1])\n",
        "        torch.nn.init.xavier_normal_(self.conv2.weight)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels = channels[1], out_channels = channels[2], kernel_size = ks[2])\n",
        "        torch.nn.init.xavier_normal_(self.conv3.weight)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(in_channels = channels[2], out_channels = channels[3], kernel_size = ks[3])\n",
        "        torch.nn.init.xavier_normal_(self.conv4.weight)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(in_channels = channels[3], out_channels = channels[4], kernel_size = ks[4])\n",
        "        torch.nn.init.xavier_normal_(self.conv5.weight)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(in_features = channels[4]*2*2, out_features = fc_neurons).to(device)\n",
        "        torch.nn.init.xavier_normal_(self.fc.weight).to(device)        \n",
        "        self.op = nn.Linear(in_features = fc_neurons, out_features = 10).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.activation(self.conv1(x)))\n",
        "        x = self.pool2(self.activation(self.conv2(x)))\n",
        "        x = self.pool3(self.activation(self.conv3(x)))\n",
        "        x = self.pool4(self.activation(self.conv4(x)))\n",
        "        x = self.pool5(self.activation(self.conv5(x)))\n",
        "        \n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = self.dropout(x)        \n",
        "        x = self.activation(self.fc(x))\n",
        "        x = self.op(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvTN4XyUKU6d"
      },
      "source": [
        "#training fucntion for CNN\n",
        "def train_model(model, criteria, optimizer, num_epochs=5, device='cuda'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        # print('Epoch {}/{}'.format(epoch, num_epochs ))\n",
        "        # print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode                \n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            if phase == 'train':\n",
        "                f = train_loader                \n",
        "            else:\n",
        "                f = val_loader\n",
        "            for inputs, labels in f:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criteria(outputs, labels)\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "            if phase == 'train':\n",
        "                epoch_loss = running_loss / len(train_data)\n",
        "                epoch_acc = running_corrects.double() /len(train_data)\n",
        "            else:\n",
        "                epoch_loss = running_loss / len(val_data)\n",
        "                epoch_acc = running_corrects.double() / len(val_data)\n",
        "            epoch_acc*=100\n",
        "            # print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best validation acc: {:4f}'.format(best_acc))\n",
        "    wandb.log({'epoch' : epoch, 'val_accuracy' : best_acc})\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    # return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbe02wyolV6P"
      },
      "source": [
        "#**Defining data loaders and training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbmKOL6fSl3W"
      },
      "source": [
        "torch.manual_seed(50)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=200, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG5LnNBBpaSB"
      },
      "source": [
        "# model = ConvNet(0.25, [32, 64, 128, 256, 512], 'ReLU', [5]*5, 512).to(device)\n",
        "# num_epochs = 10 \n",
        "# criteria = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999))\n",
        "# train_model(model, criteria, optimizer, num_epochs, 'cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_nU4jUmr9M4"
      },
      "source": [
        "#**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5m2OptMgdFT"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
        "    'parameters': {'num_filters': {'values': [16, 32, 64]},\n",
        "                  #  'filter_org': {'values': [1, 2]},\n",
        "                'dropout': {'values': [0.2, 0.25]},\n",
        "                'learning_rate': {'values': [0.0001, 0.0003]},\n",
        "                'activation': {'values': ['ReLU', 'LeakyReLU', 'ELU']},\n",
        "                'beta1': {'values': [0.9, 0.92, 0.96]}\n",
        "                }}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ4UbSe8iMxE"
      },
      "source": [
        "def train():\n",
        "    var1 = wandb.init()\n",
        "    var2 = var1.config\n",
        "\n",
        "    # channels = [var2.num_filters]\n",
        "    # for i in range(4):\n",
        "    #   channels.append(channels[i]*var2.filter_org)\n",
        "    \n",
        "    num_of_neurons_fclayer = 512\n",
        "    model = ConvNet(var2.dropout, [var2.num_filters*i for i in [1,2,4,8,16]], var2.activation, [5]*5, num_of_neurons_fclayer).to(device)\n",
        "    \n",
        "    # if var2.optimizer == 'adam':\n",
        "    #   optimizer = optim.Adam(model.parameters(), lr=var2.learning_rate, betas=(var2.beta1, 0.999))\n",
        "    # elif var2.optimizer == 'sgd':\n",
        "    #   optimizer = optim.SGD(model.parameters(), var2.learning_rate, momentum=0.9)\n",
        "    # elif var2.optimizer == 'rmsprop':\n",
        "    #   optimizer = torch.optim.RMSprop(model.parameters(), var2.learning_rate)\n",
        "    \n",
        "    num_epochs = 10 \n",
        "    criteria = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=var2.learning_rate, betas=(var2.beta1, 0.999))\n",
        "    train_model(model, criteria, optimizer, num_epochs, 'cuda')\n",
        "   \n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N32z2z76r7wP"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910 Assignment 2\")\n",
        "wandb.agent(sweep_id, train, count=5)# id: 6rlisvfb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
