{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained_CNN_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6e15d042612430c9c1d2d72c2377d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4eb347c740a745bf80cdbc9023678c19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a303098bf074b5e99805cac431fe832",
              "IPY_MODEL_ab38a8be37b04fc98045fd50fcf76dd3"
            ]
          }
        },
        "4eb347c740a745bf80cdbc9023678c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a303098bf074b5e99805cac431fe832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_662074b347e44384a18e897f694ac8fe",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7adb5b293d83489481fdaa47a1f55371"
          }
        },
        "ab38a8be37b04fc98045fd50fcf76dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_127780cb40e74a0bb910dd19b49b848a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:07&lt;00:00, 78.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5e9fc7cc44d4a409f4c2616e6c6ee82"
          }
        },
        "662074b347e44384a18e897f694ac8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7adb5b293d83489481fdaa47a1f55371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "127780cb40e74a0bb910dd19b49b848a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5e9fc7cc44d4a409f4c2616e6c6ee82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7K10oX-J674"
      },
      "source": [
        "#**Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccS87o9spZb"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XChMhh4znhZx"
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders as sf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFS2h0wwECp"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import copy\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK2Ru3w2FBjg"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X78mem-sKAhx"
      },
      "source": [
        "#**Downloading inatuaralist dataset zip file from drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h6FvpYBs0KP"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jdVoAts2F9"
      },
      "source": [
        "id = '19EA0yl7PM8i6aQTdhH0OiEyLcTsf6hmx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbpwAIzRtpBJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('nature_12K.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vo791x_KUYx"
      },
      "source": [
        "#**Unzipping the content and distributing in train, validation and test folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9c7EDQVxVPC"
      },
      "source": [
        "!apt install unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9BplLq0upK"
      },
      "source": [
        "!unzip 'nature_12K.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPjujyZ4WVU"
      },
      "source": [
        "road='/content/inaturalist_12K/'\n",
        "roadtrn=road+\"train\"\n",
        "op= road+\"trainvalsplit\"\n",
        "sf.fixed(roadtrn, op, seed=1337, fixed=100, oversample=False, group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0hY9-94KZgN"
      },
      "source": [
        "#**Preprocessing the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwzK2bv2dDC"
      },
      "source": [
        "train_data = []\n",
        "train_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/train/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "data_augmentation = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = data_augmentation(image)\n",
        "            train_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmjUJ67u2UMM"
      },
      "source": [
        "val_data = []\n",
        "val_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/val/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = transform(image)\n",
        "            val_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdxIIZjZtSTu"
      },
      "source": [
        "test_data = []\n",
        "test_label = []\n",
        "path = '/content/inaturalist_12K/val/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = transform(image)\n",
        "            test_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6MQeNA16wda"
      },
      "source": [
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', \n",
        "           'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnQKCaUzkr9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F4LVJyvLJUE"
      },
      "source": [
        "#**Multiple Pre-Trained models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHOPhg9FRyUi"
      },
      "source": [
        "# # Resnet50 model\n",
        "def resnet(freeze_percent):\n",
        "    counttotal = 0\n",
        "    resnet50_model = models.resnet50(pretrained=True)\n",
        "    percent_of_layers_freezed = freeze_percent #0.25\n",
        "    for param in resnet50_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in resnet50_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = resnet50_model.fc.in_features\n",
        "    resnet50_model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    return resnet50_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so-H9xWKoBqo"
      },
      "source": [
        "# # vgg16 model\n",
        "def vgg(freeze_percent):\n",
        "    vgg16_model = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = freeze_percent #0.5\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = vgg16_model.classifier[6].in_features\n",
        "    features = list(vgg16_model.classifier.children())[:-1]\n",
        "    features.extend([nn.Linear(num_features, len(classes))])\n",
        "    vgg16_model.classifier = nn.Sequential(*features)\n",
        "\n",
        "    return vgg16_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOnP6p4dPGHz"
      },
      "source": [
        "# # Alexnet model\n",
        "def alexnet(freeze_percent):\n",
        "    alexnet_model = models.alexnet(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = freeze_percent #0.25\n",
        "    for param in alexnet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in alexnet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    alexnet_model.classifier[6] = nn.Linear(4096,10)\n",
        "\n",
        "    return alexnet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7IQmz0n19U"
      },
      "source": [
        "# # Squeezenet model\n",
        "def squeezenet(freeze_percent):\n",
        "    squeezenet_model = models.squeezenet1_1(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = freeze_percent #0.25\n",
        "    for param in squeezenet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in squeezenet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    squeezenet_model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "    return squeezenet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFSoS301Pt35"
      },
      "source": [
        "# # densenet model\n",
        "def densenet(freeze_percent):\n",
        "    densenet_model = models.densenet161(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = freeze_percent #0.75\n",
        "    for param in densenet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in densenet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = densenet_model.classifier.in_features\n",
        "    densenet_model.classifier = nn.Linear(num_features, 10)\n",
        "\n",
        "    return densenet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Bv54_1Ldh4"
      },
      "source": [
        "#**Defining training function and data loaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOT335DDoPLG"
      },
      "source": [
        "def train_model(model, criteria, optimizer, train_loader, num_epochs=5, device='cuda', sweep=False):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        # print('Epoch {}/{}'.format(epoch, num_epochs ))\n",
        "        # print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "\n",
        "            if phase == 'train':\n",
        "                f = train_loader\n",
        "            else:\n",
        "                f = val_loader\n",
        "            for inputs, labels in f:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criteria(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "            if phase == 'train':\n",
        "                epoch_loss = running_loss / len(train_data)\n",
        "                epoch_acc = running_corrects.double() /len(train_data)\n",
        "            else:\n",
        "                epoch_loss = running_loss / len(val_data)\n",
        "                epoch_acc = running_corrects.double() / len(val_data)\n",
        "            epoch_acc*=100\n",
        "            # print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        if sweep:\n",
        "          wandb.log({'epoch' : epoch, 'val_accuracy' : best_acc})\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best validation acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    #return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ePU9pOmL31D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=200, shuffle=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrBez5w_LmcQ"
      },
      "source": [
        "#**Training the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv5_ucy7oQRq"
      },
      "source": [
        "# num_epochs = 10\n",
        "fp = 0.25\n",
        "# model = resnet(fp).to(device)\n",
        "# # model = vgg(fp).to(device)\n",
        "# # model = alexnet(fp).to(device)\n",
        "# # model = squeezenet(fp).to(device)\n",
        "# # model = densenet(fp).to(device)\n",
        "# criteria = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.96,0.999))\n",
        "# train_model(model, criteria, optimizer, train_loader, num_epochs, 'cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51gN6Onf7WJ"
      },
      "source": [
        "#**Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWtgHGb_pUY"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
        "    'parameters': {'model': {'values': ['densenet', 'resnet', 'vgg16', 'squeezenet', 'alexnet']},\n",
        "                'learning_rate': {'values': [0.0001, 0.0003]},\n",
        "                'beta1': {'values': [0.9, 0.92, 0.96]},\n",
        "                'freeze_percent': {'values': [0.25, 0.5, 0.75]},\n",
        "                'batch_size': {'values': [25, 50, 100]}\n",
        "                }}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPlS0ZT1_uc4"
      },
      "source": [
        "def train():\n",
        "    var1 = wandb.init()\n",
        "    var2 = var1.config\n",
        "        \n",
        "    if var2.model == 'densenet':\n",
        "        model = densenet(var2.freeze_percent).to(device)\n",
        "    if var2.model == 'resnet':\n",
        "        model = resnet(var2.freeze_percent).to(device)\n",
        "    if var2.model == 'vgg16':\n",
        "        model = vgg(var2.freeze_percent).to(device)\n",
        "    if var2.model == 'squeezenet':\n",
        "        model = squeezenet(var2.freeze_percent).to(device)\n",
        "    if var2.model == 'alexnet':\n",
        "        model = alexnet(var2.freeze_percent).to(device)\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=var2.batch_size, shuffle=True)\n",
        "\n",
        "    num_epochs = 5\n",
        "    criteria = nn.CrossEntropyLoss() \n",
        "    optimizer = optim.Adam(model.parameters(), lr=var2.learning_rate, betas=(var2.beta1, 0.999))\n",
        "    train_model(model, criteria, optimizer, train_loader, num_epochs, 'cuda', True)\n",
        "   \n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-3UpzSAAT8"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910 Assignment 2\")\n",
        "wandb.agent(sweep_id, train, count=25)#id: ty1meqo4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBNk1nLhgY1v"
      },
      "source": [
        "#**Evaluation on test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "b6e15d042612430c9c1d2d72c2377d1c",
            "4eb347c740a745bf80cdbc9023678c19",
            "3a303098bf074b5e99805cac431fe832",
            "ab38a8be37b04fc98045fd50fcf76dd3",
            "662074b347e44384a18e897f694ac8fe",
            "7adb5b293d83489481fdaa47a1f55371",
            "127780cb40e74a0bb910dd19b49b848a",
            "c5e9fc7cc44d4a409f4c2616e6c6ee82"
          ]
        },
        "id": "qDAmuKZXgYF0",
        "outputId": "6d98a41b-b501-46d5-8087-12f23a8e1652"
      },
      "source": [
        "num_epochs = 10\n",
        "fp = 0.25\n",
        "# model = resnet(fp).to(device)\n",
        "model = vgg(fp).to(device)\n",
        "# model = alexnet(fp).to(device)\n",
        "# model = squeezenet(fp).to(device)\n",
        "# model = densenet(fp).to(device)\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.96,0.999))\n",
        "train_model(model, criteria, optimizer, train_loader, num_epochs, 'cuda')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6e15d042612430c9c1d2d72c2377d1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553507836.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 18m 59s\n",
            "Best validation acc: 78.778779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNhiG5hGoV4U"
      },
      "source": [
        "def evaluate():\n",
        "    with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        n_class_correct = [0 for i in range(10)]\n",
        "        n_class_samples = [0 for i in range(10)]\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            for i in range(200):\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if (label == pred):\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_samples[label] += 1\n",
        "\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R_6BMDUgV2S",
        "outputId": "bfe89a51-4775-4917-e620-1990e49527fe"
      },
      "source": [
        "evaluate()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 79.3 %\n",
            "Accuracy of Amphibia: 79.0 %\n",
            "Accuracy of Animalia: 80.0 %\n",
            "Accuracy of Arachnida: 75.5 %\n",
            "Accuracy of Aves: 88.5 %\n",
            "Accuracy of Fungi: 85.5 %\n",
            "Accuracy of Insecta: 75.5 %\n",
            "Accuracy of Mammalia: 85.5 %\n",
            "Accuracy of Mollusca: 67.5 %\n",
            "Accuracy of Plantae: 81.5 %\n",
            "Accuracy of Reptilia: 74.5 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
