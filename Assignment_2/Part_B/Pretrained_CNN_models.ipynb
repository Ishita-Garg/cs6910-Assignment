{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained_CNN_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7K10oX-J674"
      },
      "source": [
        "#**Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccS87o9spZb"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XChMhh4znhZx"
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders as sf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFS2h0wwECp"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import copy\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X78mem-sKAhx"
      },
      "source": [
        "#**Downloading inatuaralist dataset zip file from drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h6FvpYBs0KP"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jdVoAts2F9"
      },
      "source": [
        "id = '19EA0yl7PM8i6aQTdhH0OiEyLcTsf6hmx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbpwAIzRtpBJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('nature_12K.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vo791x_KUYx"
      },
      "source": [
        "#**Unzipping the content and distributing in train, validation and test folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9c7EDQVxVPC"
      },
      "source": [
        "!apt install unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9BplLq0upK"
      },
      "source": [
        "!unzip 'nature_12K.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPjujyZ4WVU"
      },
      "source": [
        "road='/content/inaturalist_12K/'\n",
        "roadtrn=road+\"train\"\n",
        "op= road+\"trainvalsplit\"\n",
        "sf.fixed(roadtrn, op, seed=1337, fixed=100, oversample=False, group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0hY9-94KZgN"
      },
      "source": [
        "#**Preprocessing the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwzK2bv2dDC"
      },
      "source": [
        "train_data = []\n",
        "train_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/train/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "data_augmentation = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = data_augmentation(image)\n",
        "            train_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmjUJ67u2UMM"
      },
      "source": [
        "val_data = []\n",
        "val_label = []\n",
        "path = '/content/inaturalist_12K/trainvalsplit/val/'\n",
        "items = os.listdir(path)\n",
        "items.sort()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(10):\n",
        "    image_folder_path = path + items[i]\n",
        "    image_names = os.listdir(image_folder_path)\n",
        "    for each_image in image_names:\n",
        "        if each_image.endswith(\".jpg\"):\n",
        "            full_path = image_folder_path + '/' + each_image\n",
        "            image = Image.open(full_path)\n",
        "            image = image.resize((224,224))\n",
        "            if image.mode == 'L':\n",
        "                continue\n",
        "            normalized_image = transform(image)\n",
        "            val_data.append((normalized_image, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6MQeNA16wda"
      },
      "source": [
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', \n",
        "           'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnQKCaUzkr9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F4LVJyvLJUE"
      },
      "source": [
        "#**Multiple Pre-Trained models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHOPhg9FRyUi"
      },
      "source": [
        "# # Resnet50 model\n",
        "def resnet():\n",
        "    counttotal = 0\n",
        "    resnet50_model = models.resnet50(pretrained=True)\n",
        "    percent_of_layers_freezed = 0.25\n",
        "    for param in resnet50_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in resnet50_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = resnet50_model.fc.in_features\n",
        "    resnet50_model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    return resnet50_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so-H9xWKoBqo"
      },
      "source": [
        "# # vgg16 model\n",
        "def vgg():\n",
        "    vgg16_model = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = 0.5\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = vgg16_model.classifier[6].in_features\n",
        "    features = list(vgg16_model.classifier.children())[:-1]\n",
        "    features.extend([nn.Linear(num_features, len(classes))])\n",
        "    vgg16_model.classifier = nn.Sequential(*features)\n",
        "\n",
        "    return vgg16_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOnP6p4dPGHz"
      },
      "source": [
        "# # Alexnet model\n",
        "def alexnet():\n",
        "    alexnet_model = models.alexnet(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = 0.25\n",
        "    for param in alexnet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in alexnet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    alexnet_model.classifier[6] = nn.Linear(4096,10)\n",
        "\n",
        "    return alexnet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7IQmz0n19U"
      },
      "source": [
        "# # Squeezenet model\n",
        "def squeezenet():\n",
        "    squeezenet_model = models.squeezenet1_1(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = 0.25\n",
        "    for param in squeezenet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in squeezenet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    squeezenet_model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "    return squeezenet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFSoS301Pt35"
      },
      "source": [
        "# # densenet model\n",
        "def densenet():\n",
        "    densenet_model = models.densenet161(pretrained=True)\n",
        "    counttotal = 0\n",
        "    percent_of_layers_freezed = 0.75\n",
        "    for param in densenet_model.parameters():\n",
        "        param.requires_grad = True\n",
        "        counttotal += 1\n",
        "    count = 0\n",
        "    for param in densenet_model.parameters():\n",
        "        if count<int(percent_of_layers_freezed*counttotal):\n",
        "            param.requires_grad = False\n",
        "            count+=1\n",
        "\n",
        "    num_features = densenet_model.classifier.in_features\n",
        "    densenet_model.classifier = nn.Linear(num_features, 10)\n",
        "\n",
        "    return densenet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Bv54_1Ldh4"
      },
      "source": [
        "#**Defining training function and data loaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOT335DDoPLG"
      },
      "source": [
        "def train_model(model, criteria, optimizer, num_epochs=5, device='cuda'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs ))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "\n",
        "            if phase == 'train':\n",
        "                f = train_loader\n",
        "            else:\n",
        "                f = val_loader\n",
        "            for inputs, labels in f:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criteria(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "            if phase == 'train':\n",
        "                epoch_loss = running_loss / len(train_data)\n",
        "                epoch_acc = running_corrects.double() /len(train_data)\n",
        "            else:\n",
        "                epoch_loss = running_loss / len(val_data)\n",
        "                epoch_acc = running_corrects.double() / len(val_data)\n",
        "            epoch_acc*=100\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best validation acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    #return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ePU9pOmL31D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrBez5w_LmcQ"
      },
      "source": [
        "#**Training the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv5_ucy7oQRq"
      },
      "source": [
        "num_epochs = 10\n",
        "model = resnet().to(device)\n",
        "# model = vgg().to(device)\n",
        "# model = alexnet().to(device)\n",
        "# model = squeezenet().to(device)\n",
        "# model = densenet().to(device)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.96,0.999))\n",
        "train_model(model, criteria, optimizer, num_epochs, 'cuda')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}